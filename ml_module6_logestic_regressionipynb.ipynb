{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression\n",
        "(Assignment Questions)\n",
        "Theoretical"
      ],
      "metadata": {
        "id": "wWgntJ2X9JUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1. What is Logistic Regression, and how does it differ from Linear Regression.\n",
        "Ans:-Logistic Regression and Linear Regression are both linear models used for prediction, but they differ fundamentally in their purpose and the type of output they produce.\n",
        "\n",
        "**Linear Regression:**\n",
        "\n",
        "* **Purpose:** Predicts a continuous target variable.  It models the relationship between the independent variables and a dependent variable, assuming a linear relationship. The output is a continuous value.\n",
        "* **Output:**  A real number (e.g., predicting house prices, stock prices, temperature).\n",
        "* **Model:**  A linear equation of the form y = mx + c where 'y' is the predicted value, 'x' is the input feature(s), 'm' is the slope (coefficient), and 'c' is the y-intercept.\n",
        "* **Error Function:** Typically uses Mean Squared Error (MSE) to measure the difference between predicted and actual values.\n",
        "\n",
        "**Logistic Regression:**\n",
        "\n",
        "* **Purpose:** Predicts the probability of a categorical dependent variable.  It's primarily used for binary classification problems (where the outcome has two possible values, 0 or 1), but can be extended to multi-class classification.\n",
        "* **Output:** A probability score between 0 and 1.  This probability is then converted to a class label (0 or 1) using a threshold (typically 0.5).  e.g., predicting the probability of a customer clicking on an ad, the likelihood of a patient having a disease.\n",
        "* **Model:**  Uses a sigmoid function to transform the linear combination of input features into a probability score.  The sigmoid function maps any real-valued number to a value between 0 and 1.  The form is:  p = 1 / (1 + exp(-z)), where z is the linear combination of input features (similar to linear regression) and p is the predicted probability.\n",
        "* **Error Function:** Uses a cost function appropriate for classification, such as log-loss (cross-entropy).\n",
        "\n",
        "\n",
        "**Key Differences Summarized:**\n",
        "\n",
        "  Linear Regression                                  Logistic Regression\n",
        "\n",
        " Continuous value                                    Probability (0 to 1)\n",
        " Regression (Prediction of a continuous value)       Classification (Prediction of a class label)\n",
        " Linear equation                                     Sigmoid function applied to linear combination\n",
        " Mean Squared Error (MSE)                            Log-loss (Cross-Entropy)\n",
        "\n",
        "\n",
        "# Q2.What is the mathematical equation of Logistic Regression.?\n",
        "Ans:-The mathematical equation of Logistic Regression is:\n",
        "\n",
        "p = 1 / (1 + exp(-z))\n",
        "\n",
        "# where:\n",
        "\n",
        "p is the predicted probability of the positive class (e.g., the probability of a customer clicking on an ad).\n",
        "z is the linear combination of input features: z = w0 + w1*x1 + w2*x2 + ... + wn*xn\n",
        "\n",
        "#   where:\n",
        " w0 is the intercept (bias term)\n",
        " w1, w2, ..., wn are the weights or coefficients associated with each input feature (x1, x2, ..., xn).\n",
        " x1, x2, ..., xn are the input features.\n",
        "\n",
        "# exp() is the exponential function.\n",
        "\n",
        "Logistic regression applies a sigmoid function to a linear equation.  The sigmoid function transforms the output of the linear equation into a probability score between 0 and 1.\n",
        "\n",
        "# Q3.Why do we use the Sigmoid function in Logistic Regression.\n",
        "Ans:-def sigmoid(x):\n",
        "  \"\"\"\n",
        "  This function calculates the sigmoid of a given input.\n",
        "  \"\"\"\n",
        "  import math\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "# Example usage\n",
        "print(sigmoid(0))  # Output: 0.5\n",
        "print(sigmoid(1))  # Output: 0.7310585786300049\n",
        "print(sigmoid(-1)) # Output: 0.2689414213699951\n",
        "\n",
        "# Q4.What is the cost function of Logistic Regression.\n",
        "Ans:-The cost function of Logistic Regression is typically the log-loss (or cross-entropy) function.  There are actually two separate cost functions, one for when the actual value\n",
        "(y) is 1 and another for when it is 0.  These are then combined to form the overall cost function.\n",
        "\n",
        "\n",
        "# Q5.What is Regularization in Logistic Regression? Why is it needed.\n",
        "Ans:-Regularization in logistic regression is a technique used to prevent overfitting. Overfitting occurs when a model learns the training data too well, including its noise and outliers,\n",
        "leading to poor performance on unseen data. Regularization adds a penalty term to the cost function, discouraging the model from assigning excessively large weights to the features.\n",
        "This helps to simplify the model and improve its generalization ability.\n",
        "\n",
        "# There are two main types of regularization used in logistic regression:\n",
        "\n",
        "1. L1 Regularization (Lasso): Adds a penalty equal to the absolute value of the magnitude of coefficients.\n",
        "2. L2 Regularization (Ridge): Adds a penalty equal to the square of the magnitude of coefficients.\n",
        "\n",
        "The regularization parameter (λ or alpha) controls the strength of the penalty.  A larger λ value leads to stronger regularization, which shrinks the coefficients towards zero.\n",
        "\n",
        "# Why is regularization needed?\n",
        "\n",
        "Prevents Overfitting: The primary reason for using regularization is to prevent overfitting. By reducing the complexity of the model, it generalizes better to unseen data.\n",
        "Improves Generalization:  A regularized model performs better on new, unseen data because it's less sensitive to noise and outliers in the training data.\n",
        "Feature Selection (L1):  L1 regularization has the interesting property of performing feature selection.  It can shrink the coefficients of irrelevant features to exactly zero, effectively removing them from the model.\n",
        "Stability: Regularization improves the stability of the model, making it less sensitive to small changes in the training data.\n",
        "\n",
        "# Q6.Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "Ans:-Lasso, Ridge, and Elastic Net are regularization techniques used in linear regression (and can be adapted for other models) to prevent overfitting. They add penalty terms to the ordinary least squares (OLS) cost function, discouraging overly complex models by shrinking the coefficients towards zero.  The difference lies in how they penalize the coefficients:\n",
        "\n",
        "# Lasso Regression (L1 Regularization):\n",
        "\n",
        "Penalty Term:  λ * Σ|βi|  (where λ is the regularization parameter, and βi are the coefficients)\n",
        "Effect:  Shrinks some coefficients to exactly zero, effectively performing feature selection.  This is useful when you suspect many features are irrelevant.\n",
        "Geometry:  Uses an L1 norm (Manhattan distance) penalty, leading to a constraint region with corners.\n",
        "# Use Cases: When you want to select a subset of important features and remove redundant ones.\n",
        "\n",
        "# Ridge Regression (L2 Regularization):\n",
        "\n",
        "Penalty Term: λ * Σβi² (where λ is the regularization parameter, and βi are the coefficients)\n",
        "Effect: Shrinks all coefficients towards zero, but doesn't typically set any exactly to zero. It reduces the impact of all features.\n",
        "Geometry: Uses an L2 norm (Euclidean distance) penalty, leading to a circular constraint region.\n",
        "Use Cases:  When you have many correlated features and want to reduce their variance and multicollinearity.\n",
        "\n",
        "# Elastic Net Regression:\n",
        "\n",
        "Penalty Term:  λ * [(1 - α) * Σβi² / 2 + α * Σ|βi|] (where λ is the regularization parameter, α is the mixing parameter between L1 and L2 penalties, and βi are the coefficients)\n",
        "Effect: A combination of Lasso and Ridge.  It benefits from both feature selection (like Lasso) and handling multicollinearity (like Ridge).  α controls the balance between L1 and L2 penalties.\n",
        "Geometry:  A combination of both L1 and L2 constraint regions.\n",
        "# Use Cases:  A flexible option when unsure whether to use Lasso or Ridge. Often preferred due to its flexibility.\n",
        "\n",
        "\n",
        "# Q7.When should we use Elastic Net instead of Lasso or Ridge.\n",
        "Ans:-Elastic Net combines the strengths of both Lasso and Ridge regression.  Use Elastic Net when:\n",
        "\n",
        "# 1. High Multicollinearity:  If your dataset has a high degree of multicollinearity (strong correlations between predictor variables), Elastic Net is generally preferred.\n",
        " Ridge handles multicollinearity well, but Elastic Net provides a balance with Lasso's feature selection capability, making it more robust.\n",
        "2.  Many Features:  When dealing with a large number of features, Elastic Net can be advantageous.  Lasso might arbitrarily select one feature from a group of highly correlated features, while Elastic Net can distribute the effect more evenly, potentially leading to better performance.\n",
        "\n",
        "3.  Feature Selection Needed, but Multicollinearity is Present: If you need feature selection but have multicollinearity, Elastic Net provides the best of both worlds. It can shrink some coefficients to zero (like Lasso for feature selection) while handling multicollinearity (like Ridge).\n",
        "\n",
        "4.  Uncertainty about the Best Penalty Type:  Elastic Net is a good default choice if you're uncertain whether L1 (Lasso) or L2 (Ridge) regularization would be more appropriate.  The mixing parameter (alpha) allows you to control the balance, effectively letting the data determine the best combination.\n",
        "\n",
        "\n",
        " If you suspect multicollinearity or have a large number of features, and if feature selection is important, Elastic Net is a good starting point.  Otherwise, Lasso (for feature selection) or Ridge (for multicollinearity) might be sufficient.  You can always use cross-validation to compare the performance of all three methods.\n",
        "\n",
        "# Q8.What is the impact of the regularization parameter (λ) in Logistic Regression.\n",
        "Ans:-The regularization parameter (λ) in Logistic Regression controls the strength of the penalty applied to the model's coefficients.  It influences the trade-off between fitting the training data well and preventing overfitting.\n",
        "\n",
        "# Impact of λ:\n",
        "\n",
        "λ = 0: No regularization.  The model will try to fit the training data as closely as possible, which can lead to overfitting, especially with complex datasets or many features.  The coefficients may become very large.\n",
        "\n",
        " 0 < λ < ∞:  Regularization is applied.  As λ increases, the penalty on large coefficients becomes stronger.  This forces the model to shrink the coefficients towards zero.\n",
        "\n",
        " * Smaller λ values:  Less regularization. The model still emphasizes fitting the training data but with some constraint on the coefficients.\n",
        "\n",
        " * Larger λ values:  Stronger regularization. The model prioritizes simplicity and reduces the impact of individual features, leading to a smoother decision boundary. This helps prevent overfitting and improves generalization to new data.  However, excessively large λ values can lead to underfitting, where the model is too simplistic to capture the underlying patterns in the data.\n",
        "\n",
        "# Impact on coefficients:\n",
        "\n",
        " * Smaller λ:  Coefficients are allowed to be large.\n",
        " * Larger λ:  Coefficients are shrunk towards zero.  For L1 regularization (Lasso), some coefficients might become exactly zero, leading to feature selection.\n",
        "\n",
        "# Impact on model complexity:\n",
        "\n",
        "* Smaller λ: More complex model (may overfit).\n",
        "* Larger λ: Simpler model (may underfit).\n",
        "\n",
        "# Impact on bias-variance trade-off:\n",
        "\n",
        "* Smaller λ: Lower bias, higher variance (more prone to overfitting).\n",
        "* Larger λ: Higher bias, lower variance (less prone to overfitting).\n",
        "\n",
        "# Finding the optimal λ:\n",
        "\n",
        "The best value of λ is typically found using techniques like cross-validation.  You train the model on different subsets of the data and evaluate its performance on the held-out data for various λ values.  The λ value that results in the best cross-validation performance (e.g., the lowest error rate) is chosen.\n",
        "\n",
        "# Q9.What are the key assumptions of Logistic Regression.\n",
        "Ans:-# The key assumptions of Logistic Regression are:\n",
        "\n",
        "1. Binary Logistic Regression: The dependent variable should be binary (dichotomous), meaning it has only two possible outcomes (0 or 1).\n",
        "\n",
        "2. Independence of Observations: The observations should be independent of each other.  This means that the outcome of one observation should not influence the outcome of another.  Violation of this assumption can lead to biased estimates.  For example, observations from a repeated measures study violate this assumption.\n",
        "\n",
        "3. Linearity of Independent Variables and Logit: The logit of the dependent variable should have a linear relationship with the independent variables.  The logit is the natural logarithm of the odds ratio. This is often the most challenging assumption to satisfy.  Methods like plotting the independent variable against the logit of the dependent variable can help assess this. Transforming variables can be applied if this assumption is not met.\n",
        "\n",
        "4. No Multicollinearity:  The independent variables should not be highly correlated with each other.  High multicollinearity can make it difficult to estimate the individual effects of the independent variables and inflate the standard errors of the coefficients.  Methods to deal with this include principal component analysis or removing some of the correlated predictors.\n",
        "\n",
        "5. Large Sample Size: Logistic regression models generally perform better with larger sample sizes. A larger sample helps to provide more stable estimates of the model coefficients and improve the model's overall reliability.\n",
        "\n",
        "6. No Extreme Outliers: Outliers can distort the model's fit.  It's important to identify and potentially address extreme outliers in your data.  Outliers can be handled by removing them, transforming the variable, or using robust methods.\n",
        "\n",
        "7. Absence of Overfitting:  A model that overfits the data will perform well on the training data but poorly on new, unseen data. Techniques like regularization and cross-validation can help prevent overfitting.\n",
        "\n",
        "# Q10.What are some alternatives to Logistic Regression for classification tasks.\n",
        "Ans:-# Some alternatives to Logistic Regression for classification tasks include:\n",
        "\n",
        "1. Support Vector Machines (SVM): Effective in high-dimensional spaces and can model complex non-linear relationships using kernel tricks.\n",
        "\n",
        "2. Decision Trees/Random Forests: Easy to interpret and visualize, handle both categorical and numerical data, and can capture non-linear interactions. Random Forests are an ensemble of decision trees that further improve accuracy and robustness.\n",
        "\n",
        "3. K-Nearest Neighbors (KNN): Simple and versatile, but computationally expensive for large datasets.\n",
        "\n",
        "4. Naive Bayes: Based on Bayes' theorem, assuming feature independence. Efficient and works well with high-dimensional data.\n",
        "\n",
        "5. Neural Networks: Powerful models that can learn complex patterns but require large amounts of data and computational resources.\n",
        "\n",
        "6. Gradient Boosting Machines (GBM) like XGBoost, LightGBM, CatBoost:  Ensemble methods that combine multiple weak learners (typically decision trees) sequentially to create a strong predictive model. Often provide state-of-the-art performance.\n",
        "\n",
        "# Q11.What are Classification Evaluation Metrics.\n",
        "Ans:-Classification evaluation metrics quantify the performance of a classification model.  Here's a breakdown of common ones:\n",
        "\n",
        "Accuracy:  The most intuitive metric, representing the proportion of correctly classified instances.  However, it can be misleading when dealing with imbalanced datasets (where one class significantly outnumbers others).\n",
        "Formula: (True Positives + True Negatives) / Total Number of Instances\n",
        "\n",
        "Precision:  Measures the proportion of correctly predicted positive instances out of all instances predicted as positive.  It focuses on the quality of positive predictions.\n",
        "Formula: True Positives / (True Positives + False Positives)\n",
        "\n",
        "Recall (Sensitivity or True Positive Rate): Measures the proportion of correctly predicted positive instances out of all actual positive instances.  It focuses on the ability of the model to identify all positive instances.\n",
        "Formula: True Positives / (True Positives + False Negatives)\n",
        "\n",
        "F1-Score:  The harmonic mean of precision and recall.  Provides a balanced measure that considers both false positives and false negatives. Useful when you need to balance precision and recall.\n",
        "Formula: 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "Specificity (True Negative Rate): Measures the proportion of correctly predicted negative instances out of all actual negative instances.\n",
        "Formula: True Negatives / (True Negatives + False Positives)\n",
        "\n",
        "ROC Curve (Receiver Operating Characteristic Curve): Plots the true positive rate (recall) against the false positive rate at various classification thresholds.  The area under the ROC curve (AUC) is a summary measure of the model's ability to distinguish between classes.  A higher AUC indicates better performance.\n",
        "\n",
        "AUC-ROC (Area Under the ROC Curve):  A single number summarizing the ROC curve.  Higher values indicate better discrimination between classes (0.5 represents random guessing, 1 represents perfect classification).\n",
        "\n",
        "Log Loss (Cross-Entropy Loss): Measures the uncertainty of the model's predictions.  Lower values are better.  It penalizes confident incorrect predictions more heavily.\n",
        "\n",
        "Confusion Matrix: A table that visualizes the performance of a classification model by showing the counts of true positives, true negatives, false positives, and false negatives. It helps in understanding the types of errors made by the model.\n",
        "\n",
        "\n",
        "Choosing the Right Metric:\n",
        "\n",
        "# The best metric depends on the specific problem and its context:\n",
        "Imbalanced datasets:  Precision, recall, F1-score, and AUC-ROC are often more informative than accuracy.\n",
        "Medical diagnosis (minimizing false negatives is crucial): Recall is particularly important.\n",
        "Spam detection (minimizing false positives is crucial): Precision is more important.\n",
        "General classification tasks with balanced datasets: Accuracy, F1-score, and AUC-ROC are commonly used.\n",
        "\n",
        "# Q12.How does class imbalance affect Logistic Regression.\n",
        "Ans:- 1. Biased Predictions: In the presence of class imbalance, the model may become biased towards the majority class. Since the majority class dominates the training data, the model learns to predict the majority class more often, even if it means misclassifying instances of the minority class.  This is because the model tries to minimize overall error, and a small number of errors in the minority class may have less impact on the total error than errors in the majority class.\n",
        "\n",
        "2. Poor Performance on Minority Class: The primary concern with class imbalance is poor performance on the minority class.  Metrics like accuracy can be misleading because a model that always predicts the majority class can achieve high accuracy if the majority class is prevalent, but it won't be useful for identifying instances of the minority class.\n",
        "\n",
        "3. Misleading Evaluation Metrics:  Accuracy can be misleading when dealing with class imbalances.\n",
        "#     Consider a dataset with 99% of data points belonging to Class A and 1% belonging to Class B.  A model that always predicts Class A will have 99% accuracy, but its ability to correctly identify instances of Class B is nonexistent.  Other metrics like precision, recall, F1-score, and AUC-ROC provide a more comprehensive view of performance in these situations.\n",
        "\n",
        "# Mitigating the Effects of Class Imbalance:\n",
        "\n",
        "1. Resampling Techniques:\n",
        "#     * Oversampling the Minority Class: Creating synthetic samples of the minority class (e.g., SMOTE - Synthetic Minority Over-sampling Technique) to balance the class distribution.\n",
        "#     * Undersampling the Majority Class: Removing some samples from the majority class to balance the dataset.  However, this approach can lead to information loss.\n",
        "\n",
        "2. Cost-Sensitive Learning: Assigning different misclassification costs to different classes.  The model is penalized more for misclassifying instances of the minority class, encouraging it to pay more attention to this class.\n",
        "\n",
        "3. Data Augmentation: Generate new samples from existing minority class data through various methods depending on the data type.\n",
        "\n",
        "4. Ensemble Methods: Utilize ensemble methods like bagging or boosting to combine predictions from multiple models.  These methods can be more robust to class imbalance.\n",
        "\n",
        "5. Anomaly Detection: Consider framing the problem as an anomaly detection task, where the minority class is considered an anomaly.\n",
        "\n",
        "6. Algorithm Selection: Choose algorithms less susceptible to class imbalance.\n",
        "\n",
        "# Q13.What is Hyperparameter Tuning in Logistic Regression.\n",
        "Ans:-Hyperparameter tuning in logistic regression involves finding the optimal values for parameters that are not learned directly from the data during model training. These parameters control the learning process and the model's behavior.  In logistic regression, key hyperparameters include:\n",
        "\n",
        "# 1. Regularization Parameter (C or lambda):  Controls the strength of regularization (L1 or L2).\n",
        "* Smaller C (larger lambda): Stronger regularization, preventing overfitting but potentially increasing bias (underfitting).\n",
        "* Larger C (smaller lambda): Weaker regularization, allowing the model to fit the training data more closely, but potentially increasing variance (overfitting).\n",
        "\n",
        "# 2. Penalty (L1 or L2):\n",
        "* L1 (Lasso): Adds a penalty proportional to the absolute values of the coefficients.  It can lead to feature selection by setting some coefficients to zero.\n",
        "* L2 (Ridge): Adds a penalty proportional to the square of the coefficients.  It shrinks the coefficients towards zero but typically doesn't set them exactly to zero.\n",
        "\n",
        "3. Solver: The algorithm used to optimize the cost function (e.g., 'liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'). Different solvers have different strengths and weaknesses in terms of speed, convergence, and scalability to large datasets.\n",
        "\n",
        "4. Maximum Iterations:  The maximum number of iterations allowed for the solver to converge.  If the solver doesn't converge within the specified number of iterations, the optimization process stops prematurely.\n",
        "\n",
        "# Methods for Hyperparameter Tuning:\n",
        "\n",
        "1. Grid Search:  Exhaustively searches through a predefined set of hyperparameter values. It evaluates the model's performance for each combination of values and selects the combination that yields the best performance.\n",
        "\n",
        "2. Random Search: Randomly samples hyperparameter values from a specified range.  It's often more efficient than grid search, especially for a large number of hyperparameters.\n",
        "\n",
        "3. Bayesian Optimization: Uses a probabilistic model to guide the search for optimal hyperparameters. It intelligently explores the hyperparameter space by considering the past evaluations, and it's often more efficient than grid search and random search for complex models.\n",
        "\n",
        "4. Cross-Validation: Used in conjunction with any of the above hyperparameter tuning methods. It involves dividing the data into several folds, training the model on a subset of folds, and evaluating it on the remaining fold. This helps to estimate the model's performance on unseen data and avoid overfitting to the training set.\n",
        "\n",
        "# Example (using GridSearchCV from scikit-learn):\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Assuming 'X' is your feature matrix and 'y' is your target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
        "grid_search = GridSearchCV(LogisticRegression(solver = 'liblinear'), param_grid, cv=5) # 'liblinear' solver supports L1 penalty\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation Score: {best_score}\")\n",
        "\n",
        "model = LogisticRegression(**best_params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Q14.What are different solvers in Logistic Regression? Which one should be used.\n",
        "Ans:- Different solvers in Logistic Regression and when to use them:\n",
        "\n",
        "# 1. 'liblinear':\n",
        "- Suitable for small datasets.\n",
        "- Good for L1 and L2 regularization.\n",
        "- Doesn't support multinomial loss.\n",
        "\n",
        "# 2. 'newton-cg', 'lbfgs', 'sag', 'saga':\n",
        "- Suitable for multi-class problems.\n",
        "- Support L2 regularization.\n",
        "- 'newton-cg', 'lbfgs' are faster for smaller datasets.\n",
        "- 'sag', 'saga' are faster for large datasets.\n",
        "- 'sag' and 'saga' are stochastic gradient methods.\n",
        "\n",
        "\n",
        "# Which solver to use?\n",
        "\n",
        "- For small datasets with L1 or L2 regularization: 'liblinear'\n",
        "- For large datasets with L2 regularization: 'sag' or 'saga'\n",
        "- For multi-class problems: 'newton-cg', 'lbfgs', 'sag', or 'saga'\n",
        "\n",
        "# General Recommendation:\n",
        "- Start with 'liblinear' for small datasets or 'lbfgs' for medium-sized datasets.\n",
        "- If you encounter performance issues or need faster training for large datasets, consider 'sag' or 'saga'.\n",
        "- Always evaluate different solvers with your data to see which provides the best performance and stability.\n",
        "\n",
        "# Example (using 'lbfgs'):\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver='lbfgs') # Use lbfgs as default solver\n",
        "\n",
        "# Q15. How is Logistic Regression extended for multiclass classification.\n",
        "Ans:-One-vs-Rest (OvR) or One-vs-All (OvA):\n",
        "In OvR, for each class, a separate binary logistic regression model is trained.  Each model distinguishes that class from all other classes.  When making a prediction, all models are run, and the class with the highest probability is selected.\n",
        "\n",
        "# Multinomial Logistic Regression:\n",
        "Multinomial logistic regression directly models the probabilities of all classes simultaneously. It uses a softmax function to convert the linear combinations of input features into probabilities for each class, ensuring that the probabilities sum up to 1.  It's generally more accurate and efficient than OvR for multiclass problems.  Scikit-learn's `LogisticRegression` supports multinomial logistic regression when you set the `multi_class` parameter to 'multinomial'.\n",
        "\n",
        "Example (Multinomial Logistic Regression using scikit-learn):\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')  # 'lbfgs', 'newton-cg', 'sag', 'saga' are suitable solvers for multinomial\n",
        "model.fit(X_train, y_train)  # X_train and y_train are your training data\n",
        "predictions = model.predict(X_test)  # Predict on test data\n",
        "\n",
        "# Q16.What are the advantages and disadvantages of Logistic Regression.\n",
        "Ans:-Advantages of Logistic Regression:\n",
        "\n",
        "1. Simplicity and Interpretability: Logistic regression is relatively easy to understand and interpret.  The coefficients of the model provide insights into the relationship between the input features and the outcome.  You can easily see which features are positively or negatively associated with the target variable and the magnitude of their influence.\n",
        "\n",
        "2. Efficiency: Logistic regression is computationally efficient and can be trained relatively quickly, especially for smaller to medium-sized datasets.\n",
        "\n",
        "3. No Feature Scaling Required: Unlike some other machine learning algorithms (e.g., k-nearest neighbors, support vector machines), logistic regression doesn't require feature scaling (standardization or normalization) to perform well.\n",
        "\n",
        "4. Probability Estimates:  Logistic regression provides probability estimates for the predicted class, which can be valuable for decision-making and risk assessment.\n",
        "\n",
        "5. Handles High-Dimensional Data: Logistic regression can handle datasets with a large number of features.\n",
        "\n",
        "6. Well-Established: Logistic regression is a well-established and widely used technique with mature implementation and extensive documentation.\n",
        "\n",
        "\n",
        "\n",
        "Disadvantages of Logistic Regression:\n",
        "\n",
        "1. Assumes Linearity:  Logistic regression assumes a linear relationship between the independent variables and the log-odds of the dependent variable. If the relationship is non-linear, the model's accuracy may be limited. Non-linear relationships may require feature engineering or alternative models.\n",
        "\n",
        "2. Sensitive to Outliers: Outliers can disproportionately influence the model's coefficients and reduce its accuracy.  Outlier detection and handling are important steps in the data preprocessing phase.\n",
        "\n",
        "3. Prone to Overfitting: With a large number of features relative to the number of samples, logistic regression can overfit the training data, leading to poor generalization to new data.  Regularization techniques can help mitigate this problem.\n",
        "\n",
        "4. Limited Complexity: Logistic regression can only model linear relationships between features and the target variable. It can't capture complex interactions between features, requiring feature engineering to create interaction terms or more complex models (e.g., decision trees, support vector machines, neural networks) for non-linear relationships.\n",
        "\n",
        "5. Multicollinearity Issues:  Highly correlated predictor variables can lead to unstable coefficient estimates and inflated standard errors.  Addressing multicollinearity is crucial to obtain reliable results.\n",
        "\n",
        "6. Class Imbalance Problems: In datasets where one class significantly outnumbers others, logistic regression may become biased toward the majority class.  Addressing class imbalance through resampling, cost-sensitive learning, or other methods is important for reliable performance.\n",
        "\n",
        "# Q17.What are some use cases of Logistic Regression.\n",
        "Ans:- 1. Credit Scoring:  Predicting the likelihood of loan defaults.\n",
        "2. Customer Churn Prediction: Identifying customers likely to cancel their subscriptions or switch providers.\n",
        "3. Medical Diagnosis: Predicting the probability of a patient having a particular disease based on symptoms and medical history.\n",
        "4. Spam Detection: Classifying emails as spam or not spam.\n",
        "5. Image Recognition (basic): Classifying images into different categories (e.g., cat vs. dog in a simplified scenario).\n",
        "6. Fraud Detection: Identifying potentially fraudulent transactions.\n",
        "7. Click-Through Rate Prediction: Estimating the probability that a user will click on an online advertisement.\n",
        "8. Marketing Response Modeling: Predicting the likelihood of a customer responding to a marketing campaign.\n",
        "9. Risk Assessment: Evaluating the risk of an event occurring (e.g., insurance claims, default on a loan).\n",
        "10. Sentiment Analysis: Classifying text as positive, negative, or neutral.\n",
        "\n",
        "# Q18. What is the difference between Softmax Regression and Logistic Regression.\n",
        "Ans:-Logistic Regression:\n",
        " Binary classification: Predicts the probability of an instance belonging to one of two classes (0 or 1).\n",
        " Sigmoid function: Uses the sigmoid function to map the linear combination of input features to a probability between 0 and 1.\n",
        "\n",
        "# Softmax Regression:\n",
        " Multi-class classification: Predicts the probability of an instance belonging to one of multiple classes (K > 2).\n",
        " Softmax function: Uses the softmax function to map the linear combination of input features to a probability distribution over all K classes. The softmax function ensures that the predicted probabilities for all classes sum up to 1.\n",
        "\n",
        "# Q19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification.\n",
        "Ans:- Softmax Regression:\n",
        " Preferred for multi-class problems where the classes are mutually exclusive (an instance belongs to only one class).\n",
        " Models the probabilities of all classes simultaneously, providing a more accurate and efficient solution compared to OvR.\n",
        " Generally better calibrated probabilities for each class.\n",
        " Often the default choice for multiclass problems with `LogisticRegression`.\n",
        "\n",
        "\n",
        "# One-vs-Rest (OvR):\n",
        " Can be used when classes might not be strictly mutually exclusive.\n",
        " Might be slightly more interpretable since each class has its own separate model.\n",
        " Can be useful as an alternative to softmax regression for multiclass classification, but it is generally outperformed by softmax.\n",
        "\n",
        "# In Summary:\n",
        " For most typical multiclass classification scenarios where the classes are mutually exclusive (an instance can belong to only one class), softmax regression is the better choice due to its greater efficiency and accuracy.\n",
        " Reserve OvR for situations where the classes aren't mutually exclusive, or if you require a very straightforward method for multiclass classification.\n",
        " Using cross-validation or other performance metrics on a held-out dataset to compare their performances is a good practice.\n",
        "\n",
        "# Q20. How do we interpret coefficients in Logistic Regression?\n",
        "Ans:- In logistic regression, coefficients represent the change in the log-odds of the outcome variable for a one-unit change in the predictor variable, holding other variables constant.\n",
        "\n",
        "# Example:\n",
        "Suppose you have a logistic regression model predicting the probability of a customer clicking on an ad.\n",
        "One of the predictor variables is the age of the customer.\n",
        "If the coefficient for age is 0.05, it means that for every one-year increase in age, the log-odds of clicking on the ad increase by 0.05.\n",
        "\n",
        "# To interpret this in terms of probability, you can use the following formula:\n",
        "\n",
        "Probability = 1 / (1 + exp(-log-odds))\n",
        "\n",
        "So, a coefficient of 0.05 translates to an increase in probability that depends on the initial probability.\n",
        "For example, if the initial log-odds is 0 (probability of 0.5), a 0.05 increase would result in slightly higher probability.\n"
      ],
      "metadata": {
        "id": "9piy9oVE9Xih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical"
      ],
      "metadata": {
        "id": "CFztGzYhHEBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Apply Logistic Regression\n",
        "model = LogisticRegression(max_iter=200)  # Increased max_iter for convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjdWwX4GHEVw",
        "outputId": "3bb490bf-a946-4aad-a2c1-b1018a43df43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Apply Logistic Regression with L1 regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='l1',\n",
        "    solver='saga',  # 'saga' solver supports L1 penalty\n",
        "    max_iter=200\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tZ_r_iKeJHG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8788605c-96f7-42c6-8159-1cd6c71b76f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3.Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Apply Logistic Regression with L2 regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',  # L2 regularization (Ridge)\n",
        "    solver='lbfgs',  # lbfgs solver works well with l2\n",
        "    max_iter=200\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 6: Print model coefficients\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhF1iaK9Jqco",
        "outputId": "bef2fbe6-16ac-46d7-cb5d-65e101205edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L2 Regularization: 100.00%\n",
            "\n",
            "Model Coefficients:\n",
            "[[-0.40538561  0.86892188 -2.277875   -0.95680118]\n",
            " [ 0.4664269  -0.37487908 -0.18745251 -0.72127094]\n",
            " [-0.06104129 -0.4940428   2.46532752  1.67807213]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4.Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Apply Logistic Regression with Elastic Net regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',      # 'saga' solver is needed for elasticnet\n",
        "    l1_ratio=0.5,       # Mixing parameter (0 = pure L2, 1 = pure L1, 0.5 = equal mix)\n",
        "    max_iter=500\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 6: Print model coefficients\n",
        "print(\"\\nModel Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWi8MKU4J8VX",
        "outputId": "aede9564-e0a3-48dd-8867-b5f5ad3bec77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 100.00%\n",
            "\n",
            "Model Coefficients:\n",
            "[[ 0.29176377  1.69215272 -2.35461745 -0.56786888]\n",
            " [ 0.          0.          0.         -0.45421296]\n",
            " [-0.92988173 -0.91242028  2.5108975   2.00286014]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5.C Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Apply Logistic Regression with One-vs-Rest (OvR) strategy\n",
        "model = LogisticRegression(\n",
        "    multi_class='ovr',  # One-vs-Rest strategy\n",
        "    solver='lbfgs',     # lbfgs solver works well with OvR\n",
        "    max_iter=200\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with OvR Multiclass Classification: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 6: Print model coefficients\n",
        "print(\"\\nModel Coefficients for each class:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEkX00hJKMAd",
        "outputId": "7fad1502-85df-4ed2-8487-1bf685e8732b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with OvR Multiclass Classification: 95.56%\n",
            "\n",
            "Model Coefficients for each class:\n",
            "[[-0.43107698  0.84570847 -2.15658006 -0.88940818]\n",
            " [-0.21827977 -2.20732327  0.54831799 -0.97010715]\n",
            " [-0.29108948 -0.36713148  2.63682215  1.97588514]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Set up the parameter grid for C and penalty\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],      # Regularization strengths to try\n",
        "    'penalty': ['l1', 'l2'],            # L1 or L2 penalty\n",
        "    'solver': ['saga'],                 # 'saga' supports both l1 and l2 penalties\n",
        "    'max_iter': [500]                   # Enough iterations to converge\n",
        "}\n",
        "\n",
        "# Step 4: Create the Logistic Regression model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Step 5: Apply GridSearchCV\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Get the best parameters and best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Step 7: Predict on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Step 8: Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Parameters found: {best_params}\")\n",
        "print(f\"Test Set Accuracy with Best Parameters: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDTvtXa9KatH",
        "outputId": "a25527f3-9feb-400f-93df-4a12ed2b9a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters found: {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Test Set Accuracy with Best Parameters: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7.Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Create the Logistic Regression model\n",
        "model = LogisticRegression(\n",
        "    solver='lbfgs',     # Good solver for multiclass\n",
        "    max_iter=200\n",
        ")\n",
        "\n",
        "# Step 3: Define Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 4: Evaluate model using cross-validation\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Step 5: Print individual fold accuracies and average accuracy\n",
        "print(\"Accuracies for each fold:\", scores)\n",
        "print(f\"Average Accuracy: {np.mean(scores) * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOZ6ZHn_Kq9e",
        "outputId": "07a89d74-b4a0-46c2-aab3-968ebaa81fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies for each fold: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
            "Average Accuracy: 96.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset from CSV\n",
        "# Replace 'your_dataset.csv' with the actual file name or path\n",
        "try:\n",
        "    data = pd.read_csv('your_dataset.csv')  # Replace with your actual file name or path\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'your_dataset.csv' not found. Please provide the correct file name or path.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Step 2: Separate features (X) and target labels (y)\n",
        "# Replace 'target_column' with the actual name of the target column in your dataset\n",
        "try:\n",
        "    X = data.drop('target_column', axis=1)  # Replace 'target_column' with your target column name\n",
        "    y = data['target_column']             # Replace 'target_column' with your target column name\n",
        "except KeyError:\n",
        "    print(\"Error: 'target_column' not found in the dataset. Please provide the correct target column name.\")\n",
        "    exit()\n",
        "\n",
        "# Step 3: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 6: Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9gi_BMML8-",
        "outputId": "7ccfb60c-bb7c-4244-cf7c-f71c92891998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'your_dataset.csv' not found. Please provide the correct file name or path.\n",
            "Error: 'target_column' not found in the dataset. Please provide the correct target column name.\n",
            "Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Define the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "# Step 4: Set up the hyperparameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(0.01, 10),          # Regularization strength (C values between 0.01 and 10)\n",
        "    'penalty': ['l1', 'l2'],         # L1 or L2 penalty\n",
        "    'solver': ['liblinear', 'saga']  # solvers that support both L1 and L2\n",
        "}\n",
        "\n",
        "# Step 5: Apply RandomizedSearchCV to tune hyperparameters\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,                      # Number of iterations (tries 20 random combinations)\n",
        "    cv=5,                           # 5-fold cross-validation\n",
        "    random_state=42,\n",
        "    scoring='accuracy'              # Accuracy as the evaluation metric\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Get the best parameters and the best model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Step 7: Evaluate the model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 8: Print the results\n",
        "print(f\"Best Parameters found: {best_params}\")\n",
        "print(f\"Test Set Accuracy with Best Parameters: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "2gBPqoDUNOj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b4f430-493f-415f-bf7b-f5a56e066618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters found: {'C': np.float64(8.334426408004218), 'penalty': 'l2', 'solver': 'saga'}\n",
            "Test Set Accuracy with Best Parameters: 100.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target labels\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Step 4: Apply One-vs-One (OvO) strategy\n",
        "ovo_model = OneVsOneClassifier(logreg)\n",
        "\n",
        "# Step 5: Train the model\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "\n",
        "# Step 7: Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy using One-vs-One (OvO) Multiclass Logistic Regression: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADl7vYNlQ9dd",
        "outputId": "8a4f65eb-5e76-4b48-dbf1-1e1b6bc65937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy using One-vs-One (OvO) Multiclass Logistic Regression: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset (using breast cancer dataset as an example)\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (binary: 0 = malignant, 1 = benign)\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 6: Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Step 7: Visualize confusion matrix using heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Malignant\", \"Benign\"], yticklabels=[\"Malignant\", \"Benign\"])\n",
        "plt.title('Confusion Matrix for Binary Classification')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "m5bi_goYRQrN",
        "outputId": "a7284a11-135e-4ac9-e801-4bceaef0af2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.08%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q12.Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Step 1: Load the dataset (using breast cancer dataset as an example)\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (binary: 0 = malignant, 1 = benign)\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Calculate performance metrics\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print the results\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Recall: {recall * 100:.2f}%\")\n",
        "print(f\"F1-Score: {f1 * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl-AMZECRggr",
        "outputId": "897e75c7-8bf6-42ee-8927-aadaeba61845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 97.08%\n",
            "Precision: 97.25%\n",
            "Recall: 98.15%\n",
            "F1-Score: 97.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Step 1: Create an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Train Logistic Regression model with class weights\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print results\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBHBU0aZR_Kb",
        "outputId": "319b4b94-e373-4e37-ac0f-45cf8541c3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 84.33%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.91       275\n",
            "           1       0.32      0.76      0.45        25\n",
            "\n",
            "    accuracy                           0.84       300\n",
            "   macro avg       0.65      0.81      0.68       300\n",
            "weighted avg       0.92      0.84      0.87       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q14.Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Preprocessing\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Handle missing values\n",
        "# For 'Age', we will use the median, and for 'Embarked', we will use the most frequent value\n",
        "X['Age'] = X['Age'].fillna(X['Age'].median())\n",
        "X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a preprocessing pipeline\n",
        "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline that combines preprocessing and the model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Survived', 'Survived'], yticklabels=['Not Survived', 'Survived'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hsh_yyEvSOlr",
        "outputId": "f2cc05d2-6695-45f1-c299-ae9017f64739"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "Accuracy: 0.80\n",
            "Confusion Matrix:\n",
            "[[90 15]\n",
            " [21 53]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83       105\n",
            "           1       0.78      0.72      0.75        74\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.80      0.79      0.79       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b7c9840077dd>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Age'] = X['Age'].fillna(X['Age'].median())\n",
            "<ipython-input-8-b7c9840077dd>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q15.Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Apply feature scaling (standardization)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scaling the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Scaling the test data based on the training data statistics\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 4. Train a Logistic Regression model without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=200)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the model's accuracy without scaling\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# 5. Train a Logistic Regression model with scaling\n",
        "model_with_scaling = LogisticRegression(max_iter=200)\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate the model's accuracy with scaling\n",
        "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "\n",
        "# 6. Display the results\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "print(f\"Accuracy with scaling: {accuracy_with_scaling:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QNE_mAnVqnX",
        "outputId": "2799c1f3-e671-4d3b-8c5a-948ebd1cef26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q16.Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target = 'Survived'\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_data(X):\n",
        "    # Handle missing values\n",
        "    X['Age'] = X['Age'].fillna(X['Age'].median())\n",
        "    X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])\n",
        "    return X\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Preprocess the data\n",
        "X = preprocess_data(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define numeric and categorical features\n",
        "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "\n",
        "# Create preprocessing pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline that combines preprocessing and the model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "qcrzHLDPWRyH",
        "outputId": "17cf505a-5ba8-4ed9-a6cc-7f60d0c763f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-026825f74a39>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Age'] = X['Age'].fillna(X['Age'].median())\n",
            "<ipython-input-11-026825f74a39>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Train a Logistic Regression model with custom learning rate (C=0.5)\n",
        "model = LogisticRegression(C=0.5, max_iter=200)  # C=0.5 applies regularization\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict the target values for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# 6. Display the accuracy\n",
        "print(f\"Accuracy with custom learning rate (C=0.5): {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMsoGUCJXA4t",
        "outputId": "9899cb6e-e118-4faa-f829-9fed3ed72236"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with custom learning rate (C=0.5): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q18.Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict the target values for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 6. Extract the model's coefficients (importance of features)\n",
        "coefficients = model.coef_\n",
        "\n",
        "# 7. Get the feature names (Iris dataset features)\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# 8. Create a DataFrame to show feature importance\n",
        "feature_importance = pd.DataFrame(coefficients.T, columns=[f'Class {i}' for i in range(coefficients.shape[0])],\n",
        "                                  index=feature_names)\n",
        "\n",
        "# 9. Display the feature importance\n",
        "print(\"\\nFeature Importance based on model coefficients:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# 10. Identify the most important features (highest absolute coefficient values)\n",
        "most_important_features = {}\n",
        "for i in range(coefficients.shape[0]):\n",
        "    most_important_features[f'Class {i}'] = feature_importance.iloc[:, i].abs().idxmax()\n",
        "\n",
        "# Display the most important feature for each class\n",
        "print(\"\\nMost important feature for each class based on model coefficients:\")\n",
        "for class_label, feature in most_important_features.items():\n",
        "    print(f\"{class_label}: {feature}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBRSwFbOXRCO",
        "outputId": "7e69ec1a-0485-4e13-b763-e7329af2d361"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "\n",
            "Feature Importance based on model coefficients:\n",
            "                    Class 0   Class 1   Class 2\n",
            "sepal length (cm) -0.405386  0.466427 -0.061041\n",
            "sepal width (cm)   0.868922 -0.374879 -0.494043\n",
            "petal length (cm) -2.277875 -0.187453  2.465328\n",
            "petal width (cm)  -0.956801 -0.721271  1.678072\n",
            "\n",
            "Most important feature for each class based on model coefficients:\n",
            "Class 0: petal length (cm)\n",
            "Class 1: petal width (cm)\n",
            "Class 2: petal length (cm)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa score.\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict the target values for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 6. Calculate Cohen’s Kappa Score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9K8XL94Xd7P",
        "outputId": "ca439be4-13f5-4e58-8d39-5e33e6e2c92a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Cohen's Kappa Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q20.Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classificatio\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. For binary classification, we will filter the dataset to include only two classes (class 0 and class 1)\n",
        "# We are considering class 0 (setosa) and class 1 (versicolor) for this binary classification example\n",
        "binary_classes = (y == 0) | (y == 1)  # Filter to include only class 0 and class 1\n",
        "X_binary = X[binary_classes]\n",
        "y_binary = y[binary_classes]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predict the probabilities of the positive class (class 1)\n",
        "y_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n",
        "\n",
        "# 6. Calculate precision and recall for the Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# 7. Calculate the area under the Precision-Recall curve (AUC)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# 8. Plot the Precision-Recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='b', label=f'Precision-Recall curve (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "VxjTUlCPXsiT",
        "outputId": "70da4749-75a1-4d30-a016-68851e592fdf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy.\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. For binary classification, we will filter the dataset to include only two classes (class 0 and class 1)\n",
        "binary_classes = (y == 0) | (y == 1)  # Filter to include only class 0 and class 1\n",
        "X_binary = X[binary_classes]\n",
        "y_binary = y[binary_classes]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. List of solvers to test\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "# 5. Train Logistic Regression models with different solvers and compare their accuracy\n",
        "accuracies = {}\n",
        "\n",
        "for solver in solvers:\n",
        "    # Create a Logistic Regression model with the current solver\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train, y_train)  # Train the model\n",
        "\n",
        "    # Predict the target values for the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies[solver] = accuracy\n",
        "\n",
        "# 6. Display the results\n",
        "print(\"Accuracy comparison for different solvers:\")\n",
        "for solver, accuracy in accuracies.items():\n",
        "    print(f\"Solver: {solver}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIW9VWDNYD5b",
        "outputId": "bb6f5d04-787d-43cf-f10b-22ca50483e3e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy comparison for different solvers:\n",
            "Solver: liblinear, Accuracy: 1.0000\n",
            "Solver: saga, Accuracy: 1.0000\n",
            "Solver: lbfgs, Accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q22.Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. For binary classification, we will filter the dataset to include only two classes (class 0 and class 1)\n",
        "binary_classes = (y == 0) | (y == 1)  # Filter to include only class 0 and class 1\n",
        "X_binary = X[binary_classes]\n",
        "y_binary = y[binary_classes]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predict the target values for the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 7. Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FCKesYnYdwG",
        "outputId": "532ecd3f-24e0-4a0e-bf7c-467e9f1889db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Matthews Correlation Coefficient (MCC): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling.\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. For binary classification, we will filter the dataset to include only two classes (class 0 and class 1)\n",
        "binary_classes = (y == 0) | (y == 1)  # Filter to include only class 0 and class 1\n",
        "X_binary = X[binary_classes]\n",
        "y_binary = y[binary_classes]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Train Logistic Regression on raw (unscaled) data\n",
        "model_raw = LogisticRegression(max_iter=200)\n",
        "model_raw.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predict and calculate accuracy on raw data\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "# 6. Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 7. Train Logistic Regression on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 8. Predict and calculate accuracy on standardized data\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# 9. Compare the accuracies\n",
        "print(f\"Accuracy on raw data: {accuracy_raw:.4f}\")\n",
        "print(f\"Accuracy on standardized data: {accuracy_scaled:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CliO2ZMdYsph",
        "outputId": "abc35441-415e-4761-d645-74abd4e17946"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 1.0000\n",
            "Accuracy on standardized data: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. For binary classification, we will filter the dataset to include only two classes (class 0 and class 1)\n",
        "binary_classes = (y == 0) | (y == 1)  # Filter to include only class 0 and class 1\n",
        "X_binary = X[binary_classes]\n",
        "y_binary = y[binary_classes]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Define the range of C values for regularization strength\n",
        "param_grid = {'C': np.logspace(-4, 4, 20)}  # Values of C from 10^-4 to 10^4\n",
        "\n",
        "# 5. Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# 6. Use GridSearchCV to find the optimal C using 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 7. Get the best C value and the best model\n",
        "best_C = grid_search.best_params_['C']\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 8. Evaluate the model with the best C on the test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# 9. Output the results\n",
        "print(f\"Optimal C: {best_C}\")\n",
        "print(f\"Accuracy with optimal C: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lx7sUWpY5Xz",
        "outputId": "ee843a84-b8d9-4994-8b22-4cf0db69a99a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 0.004832930238571752\n",
            "Accuracy with optimal C: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q25.Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.\n",
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. For binary classification, we will filter the dataset to include only two classes (class 0 and class 1)\n",
        "binary_classes = (y == 0) | (y == 1)  # Filter to include only class 0 and class 1\n",
        "X_binary = X[binary_classes]\n",
        "y_binary = y[binary_classes]\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate the model on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on test data: {accuracy:.4f}\")\n",
        "\n",
        "# 6. Save the trained model using joblib\n",
        "joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "\n",
        "# 7. Load the saved model using joblib\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "# 8. Make predictions using the loaded model\n",
        "y_pred_loaded_model = loaded_model.predict(X_test)\n",
        "\n",
        "# 9. Evaluate the loaded model\n",
        "accuracy_loaded_model = accuracy_score(y_test, y_pred_loaded_model)\n",
        "print(f\"Accuracy of the loaded model: {accuracy_loaded_model:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm0YpcjNZG55",
        "outputId": "d446e269-5701-4a8b-e930-823ac7337f1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 1.0000\n",
            "Accuracy of the loaded model: 1.0000\n"
          ]
        }
      ]
    }
  ]
}